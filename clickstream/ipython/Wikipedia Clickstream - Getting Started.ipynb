{
 "metadata": {
  "name": "",
  "signature": "sha256:f07341cfacc096b684d1a2d0d4d64083b0befe3fd4940c701e56e40749376f4e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Wikipedia Clickstream - Getting Started"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This post gives an introduction to working with the newly released [Wikipedia\n",
      "Clickstream](http://datahub.io/dataset/wikipedia-clickstream/resource/be85cc68-d1e6-4134-804a-fd36b94dbb82) dataset. The data shows\n",
      "how people get to a Wikipedia article and what articles they click on next. In\n",
      "other words,\n",
      "it gives a weighted network of articles, where each edge weight corresponds to\n",
      "how often people navigate from one page to another. To give an example, consider\n",
      "the figure below, which shows incoming and outgoing traffic to the \"London\"\n",
      "article.\n",
      "\n",
      "\n",
      "<img src=\"http://files.figshare.com/1923961/London_Sankey.png\" width=\"600\" >"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The example shows that most people found the \"London\" page through Google Search\n",
      "and that only a small fraction of readers went on to another article. Before\n",
      "diving into some examples of working with the data, let me give a more detailed\n",
      "explanation of how the data was collected.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data contains counts of _(referer, resource)_ pairs extracted from the\n",
      "request logs of English Wikipedia. When a client requests a resource by\n",
      "following a link or performing a search, the URI of the webpage that linked to\n",
      "the resource is included with the request in an HTTP header called the\n",
      "\"referer\". This data captures 22 million _(referer, resource)_ pairs from a\n",
      "total of 3.2 billion requests collected during the month of February 2015.\n",
      "\n",
      "The dataset only includes requests for articles in the [main\n",
      "namespace](https://en.wikipedia.org/wiki/Wikipedia:Namespace) of the desktop\n",
      "version of English Wikipedia.\n",
      "\n",
      "Referers were [mapped](https://github.com/ewulczyn/wmf/blob/31279e76525c678e62e2\n",
      "0f986824120401544b6f/clickstream/oozie/hive_query.sql#L191-L242) to a fixed set\n",
      "of values corresponding to internal traffic or external traffic from one of the\n",
      "top 5 global traffic sources to English Wikipedia, based on this scheme:\n",
      "\n",
      "* an article in the main namespace of English Wikipedia -> the article title\n",
      "* any Wikipedia page that is not in the main namespace of English Wikipedia -> _other-wikipedia_\n",
      "* an empty referer -> _other-empty_\n",
      "* a page from any other Wikimedia project -> _other-internal_\n",
      "* Google -> _other-google_\n",
      "* Yahoo -> _other-yahoo_\n",
      "* Bing -> _other-bing_\n",
      "* Facebook -> _other-facebook_\n",
      "* Twitter -> _other-twitter_\n",
      "* anything else -> _other-other_\n",
      "\n",
      "\n",
      "MediaWiki Redirects are used to forward clients from one page name to another.\n",
      "They can be useful if a particular article is referred to by multiple names, or\n",
      "has alternative punctuation, capitalization or spellings. Requests for pages\n",
      "that get redirected were mapped to the page they redirect to. For example,\n",
      "requests for 'Obama' redirect to the 'Barack_Obama' page. Redirects were\n",
      "resolved using a snapshot of the production [redirects table](https://www.mediawiki.org/wiki/Manual:Redirect_table) from February 28 2015.\n",
      "\n",
      "Redlinks are links to an article that does not exist. Either the article was\n",
      "deleted after the creation of the link or the author intended to signal the need\n",
      "for such an article. Requests for redlinks are included in the data.\n",
      "\n",
      "We attempt to exclude spider traffic by classifying user agents with the [ua-\n",
      "parser](https://github.com/tobie/ua-parser) library and a few additonal\n",
      "Wikipedia specific [filters](https://github.com/ewulczyn/wmf/blob/a541f67c92c93609a028f59d61920fef8a1f425e/clickstream/oozie/hive_query.sql#L47-L51). Furthermore, we attempt to filter out traffic from\n",
      "bots that request a page and then request all or most of the links on that page\n",
      "(BFS traversal) by setting a threshold on the rate at which a client can\n",
      "request articles with the same referer. Requests that were made at too high of\n",
      "a rate get discarded. For the exact details, see [here](https://github.com/ewulc\n",
      "zyn/wmf/blob/31279e76525c678e62e20f986824120401544b6f/clickstream/oozie/throttle\n",
      "_ip_ua_path.py) and [here](https://github.com/ewulczyn/wmf/blob/31279e76525c678e\n",
      "62e20f986824120401544b6f/clickstream/oozie/throttle_ip_ua_ref.py). The threshold\n",
      "is quite high to avoid excluding human readers who open tabs as they read. As a\n",
      "result, requests from slow moving bots are likely to remain in the data. More\n",
      "sophisticated bot detection that evaluates the clients entire set of requests is\n",
      "an avenue of future work.\n",
      "\n",
      "Finally, any _(referer, resource)_ pair with 10 or fewer observations was\n",
      "removed from the dataset.\n",
      "\n",
      "\n",
      "### Format\n",
      "The data includes the following 6 fields:\n",
      "\n",
      "- **prev_id:** if the referer does not correspond to an article in the main\n",
      "namespace of English Wikipedia, this value will be empty. Otherwise, it contains\n",
      "the unique MediaWiki page ID of the article corresponding to the referer i.e.\n",
      "the previous article the client was on\n",
      "- **curr_id:** the unique MediaWiki page ID of the article the client requested\n",
      "- **n:** the number of occurrences of the _(referer, resource)_ pair\n",
      "- **prev_title:** the result of mapping the referer URL to the fixed set of\n",
      "values described above\n",
      "- **curr_title:** the title of the article the client requested\n",
      "- **type**\n",
      "    - \"link\" if the referer and request are both articles and the referer links\n",
      "to the request\n",
      "    - \"redlink\" if the referer is an article and links to the request, but the\n",
      "request is not in the produiction enwiki.page table\n",
      "    - \"other\" if the referer and request are both articles but the referer does\n",
      "not link to the request. This can happen when clients search or spoof their\n",
      "refer"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Getting to know the Data\n",
      "\n",
      "There are various quirks in the data due to the dynamic nature of the network of\n",
      "articles in English Wikipedia and the prevalence of requests from automata. The\n",
      "following section gives a brief overview of the data fields and caveats that\n",
      "need to be kept in mind.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Loading the Data\n",
      "First lets load the data into a pandas DataFrame. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "df = pd.read_csv(\"2015_02_clickstream.tsv\", sep='\\t', header=0)\n",
      "#we won't use ids here, so lets discard them\n",
      "df = df[['prev_title', 'curr_title', 'n', 'type']]\n",
      "df.columns = ['prev', 'curr', 'n', 'type']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Top articles\n",
      "It has been possible for the public to estimate which pages get the most pageviews per month\n",
      "from the public [pageview dumps](https://dumps.wikimedia.org/other/pagecounts-raw/) that WMF releases. Unfortunately, there is no\n",
      "attempt to remove spiders and bots from those dumps. This month the \"Layer 2\n",
      "Tunneling Protocol\" was the 3rd most requested article. The logs show that this\n",
      "article was requested by a small number of clients hundreds of times per minute\n",
      "within a 4 day window. This kind of request pattern is removed from the\n",
      "clickstream data, which gives the following as the top 10 pages:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.groupby('curr').sum().sort('n', ascending=False)[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>n</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>curr</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Main_Page</th>\n",
        "      <td> 127500620</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>87th_Academy_Awards</th>\n",
        "      <td>   2559794</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Fifty_Shades_of_Grey</th>\n",
        "      <td>   2326175</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Alive</th>\n",
        "      <td>   2244781</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Chris_Kyle</th>\n",
        "      <td>   1709341</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Fifty_Shades_of_Grey_(film)</th>\n",
        "      <td>   1683892</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Deaths_in_2015</th>\n",
        "      <td>   1614577</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Birdman_(film)</th>\n",
        "      <td>   1545842</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Islamic_State_of_Iraq_and_the_Levant</th>\n",
        "      <td>   1406530</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Stephen_Hawking</th>\n",
        "      <td>   1384193</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "                                              n\n",
        "curr                                           \n",
        "Main_Page                             127500620\n",
        "87th_Academy_Awards                     2559794\n",
        "Fifty_Shades_of_Grey                    2326175\n",
        "Alive                                   2244781\n",
        "Chris_Kyle                              1709341\n",
        "Fifty_Shades_of_Grey_(film)             1683892\n",
        "Deaths_in_2015                          1614577\n",
        "Birdman_(film)                          1545842\n",
        "Islamic_State_of_Iraq_and_the_Levant    1406530\n",
        "Stephen_Hawking                         1384193"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most requested pages tend to be about media that was popular in February. The exceptions are the \"Deaths\\_in\\_2015\" article\n",
      "and the \"Alive\" disambiguation article. The \"Main\\_Page\" links to \"Deaths\\_in\\_2015\" and is the top referer to this article, which would explain the high number of requests. The fact that the \"Alive\" disambiguation page gets so many hits seems suspsect and is likely to be a fruitfull case to investigate to improve the bot filtering."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Top Referers\n",
      "The clickstream data aslo let's us investigate who the top referers to Wikipedia\n",
      "are:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.groupby('prev').sum().sort('n', ascending=False)[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>n</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>prev</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>other-google</th>\n",
        "      <td> 1494662520</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>other-empty</th>\n",
        "      <td>  347424627</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>other-wikipedia</th>\n",
        "      <td>  129619543</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>other-other</th>\n",
        "      <td>   77496915</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>other-bing</th>\n",
        "      <td>   65895496</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>other-yahoo</th>\n",
        "      <td>   48445941</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Main_Page</th>\n",
        "      <td>   29897807</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>other-twitter</th>\n",
        "      <td>   19222486</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>other-facebook</th>\n",
        "      <td>    2312328</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>87th_Academy_Awards</th>\n",
        "      <td>    1680559</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "                              n\n",
        "prev                           \n",
        "other-google         1494662520\n",
        "other-empty           347424627\n",
        "other-wikipedia       129619543\n",
        "other-other            77496915\n",
        "other-bing             65895496\n",
        "other-yahoo            48445941\n",
        "Main_Page              29897807\n",
        "other-twitter          19222486\n",
        "other-facebook          2312328\n",
        "87th_Academy_Awards     1680559"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The top referer by a large margin is Google. Next comes refererless traffic\n",
      "(usually clients using HTTPS). Then come other language Wikipedias and pages in\n",
      "English Wikipedia that are not in the main (i.e. article) namespace. Bing\n",
      "directs significanlty more traffic to Wikipedia than Yahoo. Social media\n",
      "referals are tiny compared to Google, with twitter leading 10x more requests\n",
      "to Wikipedia than Facebook."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Trending on Social Media\n",
      "Lets look at what articles where trending on Twitter:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_twitter = df[df['prev'] == 'other-twitter']\n",
      "df_twitter.groupby('curr').sum().sort('n', ascending=False)[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>n</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>curr</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Johnny_Knoxville</th>\n",
        "      <td> 198908</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Peter_Woodcock</th>\n",
        "      <td> 126259</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2002_Tampa_plane_crash</th>\n",
        "      <td> 119906</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S\u01a1n_\u0110o\u00f2ng_Cave</th>\n",
        "      <td> 116012</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>The_boy_Jones</th>\n",
        "      <td> 114401</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "                             n\n",
        "curr                          \n",
        "Johnny_Knoxville        198908\n",
        "Peter_Woodcock          126259\n",
        "2002_Tampa_plane_crash  119906\n",
        "S\u01a1n_\u0110o\u00f2ng_Cave          116012\n",
        "The_boy_Jones           114401"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I have no explanations for this, but if you find any of the tweets linking to\n",
      "these articles, I would be curious to see why they got so many click-throughs.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Most Requested Missing Pages\n",
      "Next let's look at the most popular redinks. Redlinks are links to a Wikipedia\n",
      "page that does not exist, either because it has been deleted, or because the\n",
      "author is anticipating the creation of the page. Seeing which redlinks are the\n",
      "most viewed is interesting because it gives some indication about demand for\n",
      "missing content. Since the set of pages and links is constantly changing, the\n",
      "labeling of redlinks is not an exact science. In this case, I used a static snapshot of the [page](https://www.mediawiki.org/wiki/Manual:Page_table) and\n",
      "[pagelinks](https://www.mediawiki.org/wiki/Manual:Pagelinks_table) production tables from Feb 28th to mark a page as a redlink.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_redlinks = df[df['type'] == 'redlink']\n",
      "df_redlinks.groupby('curr').sum().sort('n', ascending=False)[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>n</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>curr</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2027_Cricket_World_Cup</th>\n",
        "      <td> 6782</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Rethinking</th>\n",
        "      <td> 5279</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Chris_Soules</th>\n",
        "      <td> 5229</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Anna_Lezhneva</th>\n",
        "      <td> 3764</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Jillie_Mack</th>\n",
        "      <td> 3685</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "                           n\n",
        "curr                        \n",
        "2027_Cricket_World_Cup  6782\n",
        "Rethinking              5279\n",
        "Chris_Soules            5229\n",
        "Anna_Lezhneva           3764\n",
        "Jillie_Mack             3685"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Searching Within Wikipedia\n",
      "\n",
      " Usually, clients navigate from one article to another through follwing a link.\n",
      "The other prominent case is search. The article from which the user searched is\n",
      "also passed as the referer to the found article. Hence, you will find a high\n",
      "count of `(Wikipedia, Chris_Kyle)` tuples. People went to the \"Wikipedia\"\n",
      "article to search for \"Chris\\_Kyle\". There is not a link to the \"Chris\\_Kyle\"\n",
      "article from the \"Wikipedia\" article. Finally, it is possible that the client\n",
      "messed with their referer header. The vast majority of requests with an internal\n",
      "referer correspond to a true link."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_search = df[df['type'] == 'other']\n",
      "df_search =  df_search[df_search.prev.str.match(\"^other.*\").apply(bool) == False]\n",
      "print \"Number of searches/ incorrect referers: %d\" % df_search.n.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of searches/ incorrect referers: 106772349\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_link = df[df['type'] == 'link']\n",
      "df_link =  df_link[df_link.prev.str.match(\"^other.*\").apply(bool) == False]\n",
      "print \"Number of links followed: %d\" % df_link.n.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of links followed: 983436029\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Inflow vs Outflow\n",
      "\n",
      "You might be tempted to think that there can't be more traffic coming out of a node (ie. article) than going into a node. This is not true for two reasons. People will\n",
      "follow links in multiple tabs as they read an article. Hence, a single pageview\n",
      "can lead to multiple records with that page as the referer. The data is also\n",
      "certain to include requests from bots which we did not correctly filter out.\n",
      "Bots will often follow most, if not all, the links in the article. Lets look at\n",
      "the ratio of incoming to outgoing links for the most requested pages."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_in = df.groupby('curr').sum()  # pageviews per article\n",
      "df_in.columns = ['in_count',]\n",
      "df_out = df.groupby('prev').sum() # link clicks per article\n",
      "df_out.columns = ['out_count',]\n",
      "df_in_out = df_in.join(df_out)\n",
      "df_in_out['ratio'] = df_in_out['out_count']/df_in_out['in_count'] #compute ratio if outflow/infow"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_in_out.sort('in_count', ascending = False)[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>in_count</th>\n",
        "      <th>out_count</th>\n",
        "      <th>ratio</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>curr</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Main_Page</th>\n",
        "      <td> 127500620</td>\n",
        "      <td> 29897807</td>\n",
        "      <td> 0.234491</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>87th_Academy_Awards</th>\n",
        "      <td>   2559794</td>\n",
        "      <td>  1680559</td>\n",
        "      <td> 0.656521</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Fifty_Shades_of_Grey</th>\n",
        "      <td>   2326175</td>\n",
        "      <td>  1146354</td>\n",
        "      <td> 0.492806</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "                       in_count  out_count     ratio\n",
        "curr                                                \n",
        "Main_Page             127500620   29897807  0.234491\n",
        "87th_Academy_Awards     2559794    1680559  0.656521\n",
        "Fifty_Shades_of_Grey    2326175    1146354  0.492806"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looking at the pages with the highest ratio of outgoing to incoming traffic\n",
      "reveals how messy the data is, even after the careful data preparation\n",
      "described above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_in_out.sort('ratio', ascending = False)[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>in_count</th>\n",
        "      <th>out_count</th>\n",
        "      <th>ratio</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>curr</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>List_of_Major_League_Baseball_players_(H)</th>\n",
        "      <td> 57</td>\n",
        "      <td> 1323</td>\n",
        "      <td> 23.210526</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2001\u201302_Slovak_Superliga</th>\n",
        "      <td> 22</td>\n",
        "      <td>  472</td>\n",
        "      <td> 21.454545</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Principle_of_good_enough</th>\n",
        "      <td> 23</td>\n",
        "      <td>  374</td>\n",
        "      <td> 16.260870</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "                                           in_count  out_count      ratio\n",
        "curr                                                                     \n",
        "List_of_Major_League_Baseball_players_(H)        57       1323  23.210526\n",
        "2001\u201302_Slovak_Superliga                         22        472  21.454545\n",
        "Principle_of_good_enough                         23        374  16.260870"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All of these pages have more traversals of a single link than they have requests\n",
      "for the page to begin with.  As a post processing step, we might enforce that\n",
      "there can't be more traversals of a link than there were requests to the page.\n",
      "Better bot filtering should help reduce this issue in the future."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_post = pd.merge(df, df_in, how='left', left_on='prev', right_index=True)\n",
      "df_post['n'] = df_post[['n', 'in_count']].min(axis=1)\n",
      "del df_post['in_count']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Network Analysis\n",
      "\n",
      "We can think of Wikipedia as a network with articles as nodes and links between\n",
      "articles as edges. This network has been available for analysis via the\n",
      "production pagelinks table. But what does it mean if there is a link between\n",
      "articles that never gets traversed? What is it about the pages that send their\n",
      "readers to other pages with high probability? What makes a link enticing to\n",
      "follow? What are the cliques of articles that send lots of traffic to each\n",
      "other? These are just some of the questions, this data set allows us to\n",
      "investigate.  I'm sure you will come up with many more."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Getting the Data\n",
      "\n",
      "The dataset is released under [CC0](\n",
      "https://creativecommons.org/publicdomain/zero/1.0/). The canonical citation and\n",
      "most up-to-date version of the data can be found at:\n",
      "\n",
      "Ellery Wulczyn, Dario Taraborelli (2015). Wikipedia Clickstream. *figshare.*\n",
      "[doi:10.6084/m9.figshare.1305770](http://dx.doi.org/10.6084/m9.figshare.1305770)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}