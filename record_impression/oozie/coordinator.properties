name_node                         = hdfs://analytics-hadoop
job_tracker                       = resourcemanager.analytics.eqiad.wmnet:8032
queue_name                        = default
user = ellery


# Base path in HDFS to record impression oozie files.
# Other files will be used relative to this path.

task = record_impression

version = v0_2


job_directory  = ${name_node}/user/ellery/record_impression/oozie



oozie_directory  = ${name_node}/wmf/refinery/current/oozie

state_directory  = ${name_node}/user/ellery/record_impression/oozie/state


# HDFS path to directory where webrequest data is time bucketed.
webrequest_data_directory=${name_node}/wmf/data/wmf/webrequest


workflow_file = ${job_directory}/workflow.xml
oozie.coord.application.path=${job_directory}/coordinator.xml


freq=60
start_time=2015-10-07T06:00Z
stop_time=2050-01-01T06:00Z


hive_script = ${job_directory}/hive_query.sql
hive_site_xml = ${name_node}/wmf/refinery/current/oozie/util/hive/hive-site.xml


oozie.use.system.libpath          = true
oozie.action.external.stats.write = true